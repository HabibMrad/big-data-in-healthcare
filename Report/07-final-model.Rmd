# Modello di Cox con covariate geniche

```{r include=FALSE}
library("survival")
library("survminer")

# carico il dataset
dataset = read.table(
  "../dataset.csv",
  na.strings = ".",
  sep = "\t",
  header = T,
  row.names = NULL
)

# Rimuovo l'id della riga
dataset <- dataset[,-1]

# Converto le variabili categoriche in categorie numeriche
dataset$Diam <- ifelse(dataset$Diam == "<=2cm", 0, 1)
dataset$N <- ifelse(dataset$N == "<4", 0, 1)
dataset$ER <- ifelse(dataset$ER == "Negative", 0, 1)
dataset$Grade <- ifelse(dataset$Grade == "Poorly diff",
                        0,
                        ifelse(dataset$Grade == "Intermediate", 1, 2))
```

## Operazioni preliminari
Estraiamo dal dataset solo le feature selezionate:
```{r}
adlasso.HR = readRDS("../adlassohr.rds")
idx_genic <- c(8:77)
idx_genic <- idx_genic[adlasso.HR != 1]

# Scelgo le feature geniche in base all'adaptive lasso
dataset <- dataset[, c(1:7, idx_genic)]

```


## Modello di Cox
Fittiamo il modello di Cox utilizzando anche le covariate geniche:
```{r}
model <-
  coxph(
    formula = Surv(time, event) ~ Diam + N + ER + Grade + Age + Contig63649_RC + QSCN6L1 +
      Contig32125_RC + SCUBE2 + OXCT1 + MMP9 + RUNDC1 + KNTC2 +
      SERF1A + GPR180 + RAB6B + ZNF533 + RTN4RL1 + MTDH + Contig40831_RC +
      COL4A2 + STK32B + GPR126 + SLC2A3 + PECI.1 + ORC6L + RFC4 + MS4A7 +
      PITRM1 + IGFBP5.1 + PRC1 + Contig20217_RC + EGLN1 + ESM1,
    data = dataset
  )

summary(model)
```
Vediamo che i test statistici per la maggior parte delle covariate sono significativi e quindi i coefficienti sono effettivamente utili per la discriminazione del modello.


## Modello baseline
Costruiamo il modello baseline:
```{r}
bas <- basehaz(model, centered = FALSE)
bas.surv <- exp(-bas[, 1])
plot(
  bas$time,
  bas.surv,
  type = 's',
  col = 1,
  ylim = c(0, 1) ,
  xlim = c(0, 18),
  lty = 2,
  xlab = 'tempo (mesi)',
  ylab = 'probabilità di sopravvivenza'
)

fit <- survfit(model)
lines(x = fit$time, y = fit$surv, type='s', lwd=2, col=2, lty = 1)

basal <- readRDS("../basal-model.rds")
fit <- survfit(basal)
lines(x = fit$time, y = fit$surv, type='s', lwd=2, col=4, lty = 3)

legend("topright", c("baseline", "genic", "clinic"), col = c(1, 2, 4), lty=c(2, 1, 3))
```
Vediamo che il modello con le sole covariate cliniche da una stima estremamente ottimistica della probabilità di sopravvivenza.

## Valutazione dell'azzardo proporzionale

Dall'analisi dei residui di Schoenfeld corretti e non con il metodo di Lin ([A3][Analisi dei residui di Schoenfeld]) emerge che la variabile SCUBE2 non rispetta l'ipotesi di azzardo proporzionale, decidiamo quindi di eliminarla dal modello.

```{r}
model2 <-
  coxph(
    formula = Surv(time, event) ~ Diam + N + ER + Grade + Age + Contig63649_RC + QSCN6L1 +
      Contig32125_RC + OXCT1 + MMP9 + RUNDC1 + KNTC2 +
      SERF1A + GPR180 + RAB6B + ZNF533 + RTN4RL1 + MTDH + Contig40831_RC +
      COL4A2 + STK32B + GPR126 + SLC2A3 + PECI.1 + ORC6L + RFC4 + MS4A7 +
      PITRM1 + IGFBP5.1 + PRC1 + Contig20217_RC + EGLN1 + ESM1,
    data = dataset
  )

bas <- basehaz(model2, centered = FALSE)
bas.surv <- exp(-bas[, 1])
plot(
  bas$time,
  bas.surv,
  type = 's',
  col = 1,
  ylim = c(0, 1) ,
  xlim = c(0, 18),
  lty = 2,
  xlab = 'tempo (mesi)',
  ylab = 'probabilità di sopravvivenza'
)

fit <- survfit(model)
lines(x = fit$time, y = fit$surv, type='s', lwd=2, col=2, lty = 1)

fit <- survfit(model2)
lines(x = fit$time, y = fit$surv, type='s', lwd=2, col=3, lty = 1)

basal <- readRDS("../basal-model.rds")
fit <- survfit(basal)
lines(x = fit$time, y = fit$surv, type='s', lwd=2, col=4, lty = 3)

legend("topright", c("baseline", "genic", "genic-2", "clinic"), col = 1:4, lty=c(2, 1, 1, 3))
```

\newpage

## Calibrazione

Calcoliamo il rischio di morte al tempo t = 12 mesi, usando il modello finale.

```{r}
# Predictiveness
fit <- survfit(model2, newdata = dataset)

dataset$riskdeath <- 1 - as.numeric(summary(fit, times = 12)$surv)

dataset$event.12m <- ifelse(dataset$time <= 12 &
                             dataset$event == 1, 1, 0)

# probabilità cumulata
estmodel <- survfit(Surv(riskdeath, event.12m) ~ 1, data = dataset)
```

### Predictiveness curve

Valutiamo la calibrazione del modello tramite predictiveness curve.

```{r fig.show = 'hide'}
# Predictiveness curve del modello
plot((1 - estmodel$surv) * 100,
     estmodel$time,
     main = '',
     type = 'l',
     ylim = c(0, 1),
     lwd = 3,
     ylab = 'r',
     cex.lab = 1.7,
     cex.axis = 1.7,
     xlab = expression(paste('P(riskscore', '' <= 'r)*100')),
     xaxt = "n",
     yaxt = "n",
     frame = F
)
```
```{r eval=FALSE}
# Predictiveness curve of a useless model:
p <- sum(dataset$event.12m) / dim(dataset)[1]
lines(c(0, 100),
      c(p, p),
      lty = 2,
      lwd = 3,
      col = 'gray')
text(40, 0.1, labels = bquote(rho ==  .(round(p, 3) * 100) ~ '%'), cex = 1.7) 
# Predictiveness curve of the ideal risk predictor:
lines(c(0, (1 - p) * 100), c(0, 0), lwd = 4)
lines(c((1 - p) * 100, (1 - p) * 100), c(0, 1), lwd = 4)
lines(c((1 - p) * 100, 100), c(1, 1), lwd = 4)
```
```{r echo=FALSE}
# Predictiveness curve del modello
plot((1 - estmodel$surv) * 100,
     estmodel$time,
     main = '',
     type = 'l',
     ylim = c(0, 1),
     lwd = 3,
     ylab = 'r',
     cex.lab = 1.7,
     cex.axis = 1.7,
     xlab = expression(paste('P(riskscore', '' <= 'r)*100')),
     xaxt = "n",
     yaxt = "n",
     frame = F
)
axis(
  2,
  at = c(0, 0.2, 0.4, 0.6, 0.8, 1),
  labels = NA,
  pos = 0
)
axis(
  2,
  at = c(0, 0.2, 0.4, 0.6, 0.8, 1),
  labels = c(0, 0.2, 0.4, 0.6, 0.8, 1),
  cex.axis = 1.7,
  pos = 0
)
axis(
  1,
  at = c(0, 20, 40, 60, 80, 100),
  labels = c(0, 20, 40, 60, 80, 100),
  cex.axis = 1.7,
  pos = 0
)
# Predictiveness curve of a useless model:
p <- sum(dataset$event.12m) / dim(dataset)[1]
lines(c(0, 100),
      c(p, p),
      lty = 2,
      lwd = 3,
      col = 'gray')
text(40, 0.1, labels = bquote(rho ==  .(round(p, 3) * 100) ~ '%'), cex = 1.7) 
# Predictiveness curve of the ideal risk predictor:
lines(c(0, (1 - p) * 100), c(0, 0), lwd = 4)
lines(c((1 - p) * 100, (1 - p) * 100), c(0, 1), lwd = 4)
lines(c((1 - p) * 100, 100), c(1, 1), lwd = 4)
```

Rispetto al modello perfetto, che arriva fino al 68.1% (complementare della probabilità 31.9%), la nostra predictiveness curve ci mostra come il modello sovrastimi eccessivamente il rischio di morte del paziente.

### Brier score

Valutiamo il Brier score:
```{r}
brier_score <- mean((dataset$event.12m - dataset$riskdeath) ^ 2)

# Brier Score under strong calibration
brier_score_sc <- mean(dataset$riskdeath * (1 - dataset$riskdeath))

print(paste("Brier score: ", brier_score))
print(paste("Brier score under strong calibration: ", brier_score_sc))
```
Il valore del Brier score è più vicino allo zero che all'uno e ciò indica che il modello è ben calibrato.

\newpage

## Discriminazione

Valutiamo l'accuratezza della predizione del rischio e scegliamo poi la soglia migliore da utilizzare usando l'indice di Youden:

```{r eval = FALSE}
roc_model <- roc(dataset$event.12m, dataset$riskdeath)

Youden <- roc_model$sensitivities + roc_model$specificities - 1
optimal.cut.off <- roc_model$thresholds[Youden == max(Youden)]
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library("pROC")

roc_model <- roc(dataset$event.12m, dataset$riskdeath)

Youden <- roc_model$sensitivities + roc_model$specificities - 1
optimal.cut.off <- roc_model$thresholds[Youden == max(Youden)]

plot(
  1 - roc_model$specificities,
  roc_model$sensitivities,
  type = 'l',
  ylab = 'TPF',
  xlab = 'FPF',
  lwd = 3,
  xaxt = "n",
  yaxt = "n",
  xlim = c(0, 1),
  cex.lab = 1.7,
  frame = F
)

axis(1,
     at = c(0, 0.25, 0.5, 0.75, 1),
     labels = NA,
     pos = 0)

axis(
  1,
  at = c(0, 0.25, 0.5, 0.75, 1),
  labels = c(0, 0.25, 0.5, 0.75, 1),
  cex.axis = 1.7,
  pos = 0
)

axis(
  2,
  at = c(0, 0.25, 0.5, 0.75, 1),
  labels = c(0, 0.25, 0.5, 0.75, 1),
  cex.axis = 1.7,
  pos = 0
)

lines(x = c(0, 1), y = c(0, 1))

cbind(optimal.cut.off, Youden = max(Youden))

points(
  1 - roc_model$specificities[roc_model$thresholds == optimal.cut.off],
  roc_model$sensitivities[roc_model$thresholds == optimal.cut.off],
  pch = 0,
  cex = 1.7
)
```

```{r}
AUC <- roc_model$auc
print(AUC)
```
Con un AUC = 0.923 il modello ha un risultato molto accurato.
Il valore che massimizza la differenza tra veri e falsi positivi è derivato dallo Youden ed è pari a $0,6191$, valore sicuramente molto elevato ed identificativo come il punto di cut-off ottimale.